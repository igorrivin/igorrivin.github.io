<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Polya-Szego Evaluation: LLM Reasoning vs Formal Verification | Igor Rivin</title>
    <meta name="description" content="Evaluating frontier LLMs on classical analysis problems from Polya-Szego. Finding: 95% informal reasoning accuracy but only 2.8% complete Lean proofs.">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="../../styles.css">
    <style>
        .blog-post {
            max-width: 900px;
            margin: 0 auto;
            padding: 2rem;
        }
        .blog-header {
            margin-bottom: 3rem;
            padding-top: 100px;
        }
        .blog-title {
            font-size: 2.5rem;
            font-weight: 700;
            margin-bottom: 1rem;
            line-height: 1.2;
        }
        .blog-meta {
            color: #666;
            font-size: 0.95rem;
            margin-bottom: 2rem;
        }
        .blog-content h2 {
            font-size: 1.75rem;
            margin-top: 2.5rem;
            margin-bottom: 1rem;
            color: #1a1a1a;
            border-bottom: 2px solid #667eea;
            padding-bottom: 0.5rem;
        }
        .blog-content h3 {
            font-size: 1.35rem;
            margin-top: 2rem;
            margin-bottom: 0.75rem;
        }
        .blog-content p {
            line-height: 1.8;
            margin-bottom: 1.25rem;
            color: #333;
        }
        .blog-content table {
            width: 100%;
            border-collapse: collapse;
            margin: 1.5rem 0;
            font-size: 0.95rem;
        }
        .blog-content th, .blog-content td {
            padding: 0.75rem 1rem;
            text-align: left;
            border-bottom: 1px solid #e0e0e0;
        }
        .blog-content th {
            background: #f8f9fa;
            font-weight: 600;
        }
        .blog-content tr:hover {
            background: #f8f9fa;
        }
        .highlight-box {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 1.5rem;
            border-radius: 12px;
            margin: 2rem 0;
        }
        .highlight-box h3 {
            color: white;
            margin-top: 0;
        }
        .highlight-box p {
            color: rgba(255,255,255,0.95);
        }
        .finding-box {
            background: #f0f7ff;
            border-left: 4px solid #667eea;
            padding: 1rem 1.5rem;
            margin: 1.5rem 0;
            border-radius: 0 8px 8px 0;
        }
        .warning-box {
            background: #fffbeb;
            border-left: 4px solid #f59e0b;
            padding: 1rem 1.5rem;
            margin: 1.5rem 0;
            border-radius: 0 8px 8px 0;
        }
        .success-box {
            background: #f0fff4;
            border-left: 4px solid #38a169;
            padding: 1rem 1.5rem;
            margin: 1.5rem 0;
            border-radius: 0 8px 8px 0;
        }
        code {
            background: #f4f4f4;
            padding: 0.2rem 0.4rem;
            border-radius: 4px;
            font-size: 0.9em;
        }
        pre {
            background: #1a1a2e;
            color: #e0e0e0;
            padding: 1.5rem;
            border-radius: 8px;
            overflow-x: auto;
            margin: 1.5rem 0;
        }
        pre code {
            background: none;
            padding: 0;
            color: inherit;
        }
        .stat-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 1rem;
            margin: 2rem 0;
        }
        .stat-card {
            background: #f8f9fa;
            padding: 1.5rem;
            border-radius: 12px;
            text-align: center;
        }
        .stat-value {
            font-size: 2.5rem;
            font-weight: 700;
            color: #667eea;
        }
        .stat-label {
            font-size: 0.9rem;
            color: #666;
            margin-top: 0.5rem;
        }
        .back-link {
            display: inline-block;
            margin-bottom: 2rem;
            color: #667eea;
            text-decoration: none;
        }
        .back-link:hover {
            text-decoration: underline;
        }
    </style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-V2J6QDNPZZ"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'G-V2J6QDNPZZ');
    </script>
</head>
<body>
    <!-- Header -->
    <header class="header">
        <div class="container">
            <nav class="nav">
                <div class="logo">
                    <a href="/" style="text-decoration: none; color: inherit;"><h1>Igor Rivin</h1></a>
                </div>
                <div class="nav-links">
                    <a href="/#about">About</a>
                    <a href="/#projects">Projects</a>
                    <a href="/research/">Research</a>
                    <a href="/#contact">Contact</a>
                </div>
            </nav>
        </div>
    </header>

    <article class="blog-post">
        <a href="/" class="back-link">&larr; Back to Home</a>

        <header class="blog-header">
            <h1 class="blog-title">Polya-Szego Evaluation Report</h1>
            <p class="blog-subtitle" style="font-size: 1.25rem; color: #555; margin-bottom: 1rem;">
                LLM Mathematical Reasoning vs Formal Verification Benchmark
            </p>
            <p class="blog-meta">January 2, 2026 &bull; Research Report &bull; 10 min read</p>
        </header>

        <div class="blog-content">
            <div class="highlight-box">
                <h3>Key Finding</h3>
                <p>
                    Frontier models excel at informal mathematical reasoning (solving 95%+ of problems correctly)
                    but struggle with formal verification in Lean4 (only 2.8% complete proofs).
                    <strong>The bottleneck in AI mathematics is not understanding&mdash;it's rigorous formalization.</strong>
                </p>
            </div>

            <h2>Executive Summary</h2>
            <p>
                This project evaluated frontier language models on problems from Polya and Szego's
                <em>"Problems and Theorems in Analysis I"</em> (1925), a canonical mathematical reference.
                We assessed both informal mathematical reasoning and formal theorem proving capabilities.
            </p>

            <div class="stat-grid">
                <div class="stat-card">
                    <div class="stat-value">95.4%</div>
                    <div class="stat-label">Informal Reasoning Accuracy</div>
                </div>
                <div class="stat-card">
                    <div class="stat-value">2.8%</div>
                    <div class="stat-label">Complete Lean Proofs</div>
                </div>
                <div class="stat-card">
                    <div class="stat-value">318</div>
                    <div class="stat-label">Problems Formalized</div>
                </div>
                <div class="stat-card">
                    <div class="stat-value">0</div>
                    <div class="stat-label">Book Errors Found</div>
                </div>
            </div>

            <h2>1. Dataset Overview</h2>

            <table>
                <tr><th>Metric</th><th>Value</th></tr>
                <tr><td>Total problems extracted</td><td>626</td></tr>
                <tr><td>Problems with solutions</td><td>599</td></tr>
                <tr><td>Unique problem numbers</td><td>320</td></tr>
                <tr><td>Clean problems (good OCR)</td><td>471</td></tr>
            </table>

            <p>
                The dataset spans combinatorics, real analysis, complex analysis, and number theory
                from Parts One through Four of the book.
            </p>

            <h2>2. Informal Reasoning Evaluation</h2>

            <h3>2.1 Model Configuration</h3>
            <table>
                <tr><th>Role</th><th>Model</th><th>Provider</th></tr>
                <tr><td>Solver</td><td>DeepSeek R1 (deepseek-r1-0528)</td><td>Novita API</td></tr>
                <tr><td>Judge</td><td>DeepSeek V3.2</td><td>Novita API</td></tr>
            </table>

            <h3>2.2 Results</h3>
            <table>
                <tr><th>Score</th><th>Count</th><th>Percentage</th></tr>
                <tr><td>5/5 (Perfect)</td><td>404</td><td>85.8%</td></tr>
                <tr><td>4/5</td><td>45</td><td>9.6%</td></tr>
                <tr><td>3/5</td><td>12</td><td>2.5%</td></tr>
                <tr><td>2/5</td><td>5</td><td>1.1%</td></tr>
                <tr><td>1/5</td><td>3</td><td>0.6%</td></tr>
                <tr><td>0/5</td><td>2</td><td>0.4%</td></tr>
            </table>

            <div class="success-box">
                <strong>Overall accuracy (4-5/5):</strong> 95.4%
            </div>

            <h3>2.3 Failure Analysis</h3>
            <p>Of the 195 problems scoring below 5/5:</p>
            <ul>
                <li><strong>~99% were OCR/data quality issues</strong> (corrupted problem text, mismatched solutions)</li>
                <li><strong>~1% were genuine model limitations</strong> (8 problems)</li>
            </ul>
            <p>
                Re-evaluation of the 8 genuine failures with Gemini 3 Pro showed improvement on 5/8,
                leaving only 3 truly challenging problems.
            </p>

            <h3>2.4 The Hardest Problem: Problem 205</h3>

            <div class="finding-box">
                <strong>Problem:</strong> Prove that if f(t) is positive and increasing on [0,1],
                then all zeros of &int;<sub>0</sub><sup>1</sup> f(t)cos(zt)dt are real.
            </div>

            <p>This 1918 result by P&oacute;lya stumped DeepSeek R1 but was solved by GPT-5.2 Pro using:</p>
            <ul>
                <li>Step function approximation</li>
                <li>Enestr&ouml;m-Kakeya lemma (polynomial zero location)</li>
                <li>Hermite-Biehler theorem (relating E(z) = A(z) - iB(z) to real zeros)</li>
                <li>Hurwitz's theorem (passing to the limit)</li>
            </ul>

            <div class="warning-box">
                <strong>Insight:</strong> The problem requires synthesizing multiple advanced techniques&mdash;a
                test of mathematical creativity, not just pattern matching.
            </div>

            <h2>3. Book Solutions Verification</h2>
            <p>
                We used Gemini 2.5 Pro to critically analyze book solutions for errors, gaps, or ambiguities.
            </p>

            <h3>3.1 Results</h3>
            <table>
                <tr><th>Category</th><th>Count</th><th>Percentage</th><th>Nature</th></tr>
                <tr><td>No issues</td><td>435</td><td>92.6%</td><td>Mathematically sound</td></tr>
                <tr><td>Serious</td><td>25</td><td>5.3%</td><td>OCR/data corruption</td></tr>
                <tr><td>Moderate</td><td>9</td><td>1.9%</td><td>Pedagogical terseness</td></tr>
                <tr><td>Minor</td><td>1</td><td>0.2%</td><td>Notation conventions</td></tr>
            </table>

            <div class="success-box">
                <strong>Conclusion:</strong> No genuine mathematical errors were found in Polya-Szego.
                All "serious" issues were data quality problems in our OCR extraction pipeline, not errors
                in the 1925 text.
            </div>

            <h2>4. Lean4 Formalization Pipeline</h2>

            <h3>4.1 Model Configuration</h3>
            <table>
                <tr><th>Role</th><th>Model</th><th>Provider</th></tr>
                <tr><td>Statement Generation</td><td>DeepSeek V3.2</td><td>Novita API</td></tr>
                <tr><td>Proof Synthesis</td><td>DeepSeek-Prover-V2-671B</td><td>Novita API</td></tr>
            </table>

            <h3>4.2 Coverage Results</h3>
            <table>
                <tr><th>Metric</th><th>Value</th></tr>
                <tr><td>Problems formalized</td><td>318/320</td></tr>
                <tr><td>Coverage</td><td><strong>99.4%</strong></td></tr>
                <tr><td>Missing</td><td>2 (API failures)</td></tr>
            </table>

            <h3>4.3 Proof Quality</h3>
            <table>
                <tr><th>Status</th><th>Count</th><th>Percentage</th></tr>
                <tr><td>Complete (no <code>sorry</code>)</td><td>9</td><td>2.8%</td></tr>
                <tr><td>Partial (with <code>sorry</code>)</td><td>309</td><td>97.2%</td></tr>
            </table>

            <h3>4.4 Analysis</h3>
            <p>The low complete-proof rate (2.8%) reflects the genuine difficulty of formal theorem proving:</p>
            <ol>
                <li><strong>Mathlib gaps:</strong> Many analysis concepts lack complete Mathlib coverage</li>
                <li><strong>Proof complexity:</strong> Classical analysis proofs require intricate epsilon-delta reasoning</li>
                <li><strong>Abstraction mismatch:</strong> Informal proofs don't map directly to Lean tactics</li>
            </ol>

            <h3>Example: Complete Proof (Problem *186 - Stirling numbers)</h3>
            <pre><code>theorem problem_star186 : stirlingS2 5 3 = 25 := by native_decide</code></pre>

            <h3>Example: Partial Proof (Problem 36 - Complex series)</h3>
            <pre><code>theorem problem_36 (α : ℝ) (hα : 0 < α ∧ α < π/2) (z : ℕ → ℂ)
    (harg : ∀ n, -α ≤ (z n).arg ∧ (z n).arg ≤ α) :
    (Summable fun n : ℕ => Real.abs ((z n).re)) ↔
    Summable fun n : ℕ => Complex.abs (z n) := by
  constructor
  · intro h
    have cos_pos : 0 < Real.cos α := by
      apply Real.cos_pos_of_mem_Ioo
      exact ⟨by linarith [hα.1], hα.2⟩
    -- ... proof using cosine bounds
    sorry
  · intro h
    have : ∀ n, Real.abs ((z n).re) ≤ Complex.abs (z n) :=
      fun n => Complex.abs_re_le_abs (z n)
    exact Summable.of_nonneg_of_le (fun n => Real.abs_nonneg _) this h</code></pre>

            <h2>5. Key Findings</h2>

            <h3>5.1 Informal Reasoning is Solved (for canonical problems)</h3>
            <p>
                Frontier models achieve 95%+ accuracy on Polya-Szego. This isn't surprising&mdash;the book
                is a canonical reference likely in training data. The interesting finding is
                <strong>which problems still challenge models</strong> (Problem 205).
            </p>

            <h3>5.2 Formal Verification is the Bottleneck</h3>
            <table>
                <tr><th>Task</th><th>Success Rate</th></tr>
                <tr><td>Informal solving</td><td>95.4%</td></tr>
                <tr><td>Formal proof synthesis</td><td>2.8%</td></tr>
            </table>
            <div class="highlight-box">
                <h3>The 30x Gap</h3>
                <p>
                    This 30x gap represents the frontier of AI mathematics. Models can "understand"
                    and solve problems but cannot produce machine-checkable proofs.
                </p>
            </div>

            <h3>5.3 Data Quality Matters</h3>
            <p>
                25/471 problems (5.3%) had OCR corruption severe enough to cause evaluation failures.
                High-quality mathematical datasets require careful curation.
            </p>

            <h3>5.4 Classic Texts Remain Sound</h3>
            <p>
                Polya-Szego (1925) contains no mathematical errors detectable by modern AI review.
                This validates using historical texts as benchmarks.
            </p>

            <h2>6. Recommendations</h2>
            <ol>
                <li><strong>For benchmarking:</strong> Focus on problems that stump models (like Problem 205)
                    rather than aggregate accuracy on canonical texts.</li>
                <li><strong>For formal verification:</strong> Invest in Mathlib coverage for classical analysis
                    and better proof search algorithms.</li>
                <li><strong>For dataset curation:</strong> Implement automated OCR quality checks;
                    5% corruption rate is significant.</li>
                <li><strong>For future work:</strong> Test on less canonical texts where memorization is less likely.</li>
            </ol>

            <h2>7. Files Generated</h2>
            <table>
                <tr><th>File</th><th>Description</th></tr>
                <tr><td><code>lean_results/*.lean</code></td><td>318 Lean4 formalizations</td></tr>
                <tr><td><code>lean_results/*.json</code></td><td>Formalization metadata</td></tr>
                <tr><td><code>book_verification_full.json</code></td><td>Book solution analysis results</td></tr>
                <tr><td><code>results_grok/evaluation_results.json</code></td><td>Model evaluation scores</td></tr>
            </table>

            <hr style="margin: 3rem 0; border: none; border-top: 1px solid #e0e0e0;">

            <p style="color: #666; font-style: italic;">
                Report generated January 2, 2026. Data and code available on request.
            </p>
        </div>
    </article>

    <!-- Footer -->
    <footer class="footer">
        <div class="container">
            <div class="footer-content">
                <p>&copy; 2026 Igor Rivin. All rights reserved.</p>
                <div class="footer-links">
                    <a href="https://github.com/igorrivin" target="_blank">GitHub</a>
                    <a href="mailto:igor@dimensionreducers.com">Email</a>
                </div>
            </div>
        </div>
    </footer>

    <script src="../../script.js"></script>
</body>
</html>
